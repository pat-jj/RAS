{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MAUVE & ROUGE] ASQA & ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj20/miniconda3/envs/handbook/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/shared/eng/pj20/firas_data/multitask/combined_train_v3.pkl\", \"rb\") as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_set = set([item[\"input\"] for item in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/shared/eng/pj20/firas_data/test_datasets/results/graphllm_asqa_answerer_test_results_graph_0.5_8b.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     data \u001b[38;5;241m=\u001b[39m load_file(file_path)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     24\u001b[0m         data_ \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# new_data = []\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# if \"test_output\" in file_path:\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#     for i in range(len(data['output'])):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#         for item in data:\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#             item['answer'] = item['answers']\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/handbook/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/shared/eng/pj20/firas_data/test_datasets/results/graphllm_asqa_answerer_test_results_graph_0.5_8b.json'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "from metrics import load_file\n",
    "\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/eli5_sonnet_test_base.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/asqa_test_output_sonnet_sonnet.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/eli5_test_output_sonnet_sonnet.json\"\n",
    "# with open(\"/shared/eng/pj20/firas_data/test_datasets/results/asqa_sonnet_retrieval_top_5_base.json\", \"r\") as f:\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_asqa_answerer_test_results_all_graph_no_ret.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_asqa_answerer_test_results_no_graph.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_asqa_answerer_test_results_all_graph_no_gtoken.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/eli5_sonnet_retrieval_top_5_sure_200.jsonl\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_eli5_answerer_test_results_all_graph_3_20.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_asqa_answerer_test_results_all_graph_3_20_8b.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_asqa_answerer_test_results_all_graph_5_20_8b.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_eli5_answerer_test_results_all_graph_7_20_8b.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_asqa_answerer_test_results_all_graph_10_20_8b.json\"\n",
    "file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_asqa_answerer_test_results_graph_0.5_8b.json\"\n",
    "\n",
    "if \"jsonl\" in file_path:\n",
    "    data = load_file(file_path)\n",
    "else:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data_ = json.load(f)\n",
    "\n",
    "\n",
    "# new_data = []\n",
    "# if \"test_output\" in file_path:\n",
    "#     for i in range(len(data['output'])):\n",
    "#         new_data.append({\"output\": data['output'][i], \"answer\": data['answer'][i], \"question\": data['question'][i]})\n",
    "#     data = new_data\n",
    "\n",
    "# else:\n",
    "#     data = data['data']\n",
    "#     if \"eli5\" in file_path:\n",
    "#         for item in data:\n",
    "#             item['answer'] = item['answers']\n",
    "\n",
    "data = []\n",
    "if \"graphllm\" in file_path:\n",
    "    for item in data_:\n",
    "        if item['input'] not in train_input_set:\n",
    "            data.append({\"question\": item['input'].split(\"[Long Form] Question: \")[1].lower(), \"output\": item['prediction'].lower(), \"answer\": item['label'].lower()})\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('there are a number of players who have scored the highest goals in world football, depending on the source. according to the soccer statistic foundation, josef bican scored 805 goals, godfrey chitalu claimed 107 goals in the 1972 season, and pelé scored 767 goals recognized by the soccer statistic foundation.',\n",
       " \"the players with the highest all-time goals and highest men's and women's international football goals differ. the player with the highest all-time men's football goals is josef bican, who in 2020 was recognized by fifa, the international governing body of football, as the record scorer with an estimated 805 goals. christine sinclair has the highest goals in women's international football with 187 and is the all-time leader for international goals scored for men or women. cristiano ronaldo and ali daei are currently tied for leading goalscorer in the history of men's international football with 109.\")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['output'], data[0]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "905"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE:  35.419368439618346\n",
      "Tokenizing text...\n",
      "Featurizing tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing p: 100%|██████████| 114/114 [00:26<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text...\n",
      "Featurizing tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing q: 100%|██████████| 114/114 [00:22<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 25\n",
      "performing clustering in lower dimension = 444\n",
      "Clustering 1810 points in 445D to 90 clusters, redo 5 times, 500 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "Outer iteration 0 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 1810 points to 90 centroids: please provide at least 3510 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration 499 (2.63 s, search 2.52 s): objective=649.207 imbalance=1.487 nsplit=0       \n",
      "Objective improved: keep new clusters\n",
      "Outer iteration 1 / 5\n",
      "  Iteration 499 (5.04 s, search 4.83 s): objective=647.589 imbalance=1.515 nsplit=0       \n",
      "Objective improved: keep new clusters\n",
      "Outer iteration 2 / 5\n",
      "  Iteration 499 (7.45 s, search 7.15 s): objective=647.758 imbalance=1.612 nsplit=0       \n",
      "Outer iteration 3 / 5\n",
      "  Iteration 499 (9.87 s, search 9.46 s): objective=650.789 imbalance=1.598 nsplit=0       \n",
      "Outer iteration 4 / 5\n",
      "  Iteration 499 (12.44 s, search 11.92 s): objective=654.123 imbalance=1.676 nsplit=0       \n",
      "kmeans time: 12.45 s\n",
      "total discretization time: 12.9 seconds\n",
      "MAUVE:  87.16445715485192\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from metrics import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "normalized_data = copy.deepcopy(data)\n",
    "# for i in range(len(normalized_data)):\n",
    "#     normalized_data[i]['output'] = remove_citations(normalized_data[i]['output'])\n",
    "\n",
    "references = [' '.join((item['question'] + \" \" + item['answer'].strip()).split()[:100]).rstrip(string.punctuation) for item in normalized_data]\n",
    "predictions = [' '.join((item['question'] + \" \" + item['output'].strip()).split()[:100]).rstrip(string.punctuation) for item in normalized_data]\n",
    "\n",
    "\n",
    "print(\"ROUGE: \", compute_rouge(normalized_data))\n",
    "print(\"MAUVE: \", mauve_score(predictions, references))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Match] PopQA, TriviaQA, PubHealth, ARC-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Michael Daugherty', 'Michael Kevin Daugherty']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/popqa_sonnet_retrieval_top_5_sure_200.jsonl\"\n",
    "data = load_file(file_path)\n",
    "data[0]['golds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "from metrics import *\n",
    "from utils import *\n",
    "\n",
    "# data = load_file(\"/shared/eng/pj20/firas_data/test_datasets/results/popqa_sonnet_retrieval_top_5.jsonl\")\n",
    "# with open(\"/shared/eng/pj20/firas_data/test_datasets/pubhealth_test_output_sonnet_sonnet.json\", \"r\") as f:\n",
    "# with open(\"/shared/eng/pj20/firas_data/test_datasets/arc_c_test_output_sonnet_sonnet.json\", \"r\") as f:\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_triviaqa_answerer_test_results.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_pubhealth_answerer_test_results_all_graph.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_pubhealth_answerer_test_results.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/triviaqa_test_output_sonnet_sonnet.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_popqa_answerer_test_results_all_graph.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_triviaqa_answerer_test_results_all_graph.json\"\n",
    "\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_arc_c_answerer_test_results_all_graph.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/2wikimultihop_test_output_llama2-7b_sonnet_v3.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_2wikimultihop_answerer_test_results_all_graph_both.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_triviaqa_answerer_test_results_all_graph_ptuned.json\"\n",
    "\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_pubhealth_answerer_test_results_all_graph_both.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_pubhealth_answerer_test_results_all_graph_ptuned.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_arc_c_answerer_test_results_all_graph_both.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_pubhealth_answerer_test_results_all_graph_no_gtoken.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_pubhealth_answerer_test_results_no_graph.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_triviaqa_answerer_test_results_no_graph.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_2wikimultihop_answerer_test_results_no_graph.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_triviaqa_answerer_test_results_all_graph_no_gtoken.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_2wikimultihop_answerer_test_results_all_graph_no_gtoken.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_triviaqa_answerer_test_results_all_graph_no_plan.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_2wikimultihop_answerer_test_results_all_graph_no_plan.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_2wikimultihop_answerer_test_results_all_graph_both.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/popqa_sonnet_retrieval_top_5_sure_200.jsonl\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/pubhealth_sonnet_retrieval_top_5_sure_200.jsonl\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/arc_c_sonnet_retrieval_top_5_sure_200.jsonl\"\n",
    "\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_pubhealth_answerer_test_results_all_graph_3_20_8b.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_triviaqa_answerer_test_results_all_graph_5_20_8b.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_pubhealth_answerer_test_results_all_graph_1_20_8b.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_2wikimultihop_answerer_test_results_all_graph_5_20_8b.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_pubhealth_answerer_test_results_all_graph_5_20.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_pubhealth_answerer_test_results_all_graph_7_20_8b.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_triviaqa_answerer_test_results_all_graph_7_20.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_2wikimultihop_answerer_test_results_all_graph_7_20.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_2wikimultihop_answerer_test_results_all_graph_10_20_8b.json\"\n",
    "# \n",
    "file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_triviaqa_answerer_test_results_graph_0.7_8b.json\"\n",
    "\n",
    "if \"jsonl\" in file_path:\n",
    "    data = load_file(file_path)\n",
    "else:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data_ = json.load(f)\n",
    "\n",
    "    data = []\n",
    "    if \"graphllm\" in file_path:\n",
    "        print(\"true\")\n",
    "        if \"2wikimultihop\" not in file_path and \"pubhealth\" not in file_path and \"arc_c\" not in file_path:\n",
    "            for item in data_:\n",
    "                if item['input'] not in train_input_set:\n",
    "                    data.append({\"output\": item['prediction'].lower(), \"golds\": [d.lower() for d in item['label']]})\n",
    "        elif \"pubhealth\" in file_path or \"arc_c\" in file_path:\n",
    "            for item in data_:\n",
    "                if item['input'] not in train_input_set:\n",
    "                    data.append({\"output\": item['prediction'].lower(), \"golds\": item['label'].lower()})\n",
    "        else:\n",
    "            for item in data_:\n",
    "                data.append({\"output\": item['prediction'].lower(), \"golds\": [item['label'].lower()]})\n",
    "\n",
    "    elif \"2wikimultihop\" in file_path:\n",
    "        for i in range(len(data_['output'])):\n",
    "            data.append({\"output\": data_['output'][i].lower(), \"golds\": [data_['answer'][i].lower()]})\n",
    "    else:\n",
    "        for i in range(len(data_['output'])):\n",
    "            data.append({\"output\": data_['output'][i].lower(), \"golds\": [d.lower() for d in data_['answer'][i]]})\n",
    "\n",
    "\n",
    "# data = data[:900]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'scorpio',\n",
       " 'golds': ['skorpio',\n",
       "  'scorpio disambiguation',\n",
       "  'scorpio',\n",
       "  'scorpio (disambiguation)',\n",
       "  'scorpio',\n",
       "  'skorpio']}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [d for d in data if d[\"output\"] == \"true\" or d[\"output\"] == \"false\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 909/909 [00:00<00:00, 14543.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match:  0.6864686468646864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# golds_mapping = {\n",
    "#     \"1\": \"a\",\n",
    "#     \"2\": \"b\",\n",
    "#     \"3\": \"c\",\n",
    "#     \"4\": \"d\",\n",
    "#     \"a\": \"a\",\n",
    "#     \"b\": \"b\",\n",
    "#     \"c\": \"c\",\n",
    "#     \"d\": \"d\"\n",
    "# }\n",
    "\n",
    "\n",
    "# data_[\"metric_result\"] = []\n",
    "metric_result_1 = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    # pubhealth\n",
    "    # data_[\"metric_result\"].append(accuracy(data[i][\"output\"], data[i][\"golds\"]))\n",
    "    # triviaqa, popqa, arc-c\n",
    "    # data_[\"metric_result\"].append(match(data[i][\"output\"], data[i][\"golds\"]))\n",
    "    # if data_[\"metric_result\"][i] == 1:\n",
    "    #     data_[\"answer\"][i].append(data[i][\"output\"])\n",
    "    # result, add = cosine_match(data[i][\"output\"], data[i][\"golds\"])\n",
    "    \n",
    "    # result= match(data[i][\"output\"], golds_mapping[data[i][\"golds\"][0]])\n",
    "    if \"apolo\" in data[i][\"output\"].lower() or \"the information\" in data[i][\"output\"].lower():\n",
    "        continue\n",
    "    \n",
    "    # result, add= cosine_match(data[i][\"output\"], data[i][\"golds\"])\n",
    "    # result = f1_score(data[i][\"output\"], data[i][\"golds\"])\n",
    "    # result = accuracy(data[i][\"output\"], data[i][\"golds\"])\n",
    "    result = match(data[i][\"output\"], data[i][\"golds\"])\n",
    "    \n",
    "    metric_result_1.append(result)\n",
    "    # if add:\n",
    "    #     data_[i]['label'].append(data[i][\"output\"])\n",
    "    #     print(f\"Added: {data[i]['output']} to {data_[i]['label']}\")\n",
    "    # if add:\n",
    "    #     data_['answer'][i].append(data[i][\"output\"])\n",
    "    #     print(f\"Added: {data[i]['output']} to {data_['answer'][i]}\")\n",
    "    \n",
    "# print(\"Match: \", np.mean(data_[\"metric_result\"]))\n",
    "print(\"Match: \", np.mean(metric_result_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 100.0, 100.0, 0.0, 100.0, 100.0, 100.0, 100.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined:  0.7740628166160081\n"
     ]
    }
   ],
   "source": [
    "combined_result = []\n",
    "for i in range(len(metric_result_1)):\n",
    "    if metric_result_1[i] == 100 or metric_result[i] == 100:\n",
    "        combined_result.append(1)\n",
    "    else:\n",
    "        combined_result.append(0)\n",
    "print(\"Combined: \", np.mean(combined_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(data_, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [F1] 2Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "from metrics import *\n",
    "from utils import *\n",
    "\n",
    "# data = load_file(\"/shared/eng/pj20/firas_data/test_datasets/results/popqa_sonnet_retrieval_top_5.jsonl\")\n",
    "\n",
    "\n",
    "# with open(\"/shared/eng/pj20/firas_data/test_datasets/2wikimultihop_test_output_sonnet_sonnet.json\", \"r\") as f:\n",
    "#     data_ = json.load(f)\n",
    "\n",
    "# data = []\n",
    "# for i in range(len(data_['output'])):\n",
    "#     data.append({\"output\": data_['output'][i].lower(), \"golds\": [data_['answer'][i]]})\n",
    "    \n",
    "    \n",
    "    \n",
    "file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/graphllm_2wikimultihop_answerer_test_results_all_graph_no_plan.json\"\n",
    "# file_path = \"/shared/eng/pj20/firas_data/test_datasets/triviaqa_test_output_sonnet_sonnet.json\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    data_ = json.load(f)\n",
    "\n",
    "data = []\n",
    "if \"graphllm\" in file_path:\n",
    "    for item in data_:\n",
    "        data.append({\"output\": item['prediction'].lower(), \"golds\": [item['label'].lower()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.407665873015873\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "    # print(item[\"golds\"])\n",
    "    # print(item[\"output\"])\n",
    "    metric_result = f1_score(item[\"output\"], item[\"golds\"])\n",
    "    item[\"metric_result\"] = metric_result\n",
    "\n",
    "print(\"F1: \", np.mean([item[\"metric_result\"] for item in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj20/miniconda3/envs/handbook/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/pj20/miniconda3/envs/handbook/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Who is the mother of the director of film Polish-Russian War (Film)?',\n",
       " 'ctxs': [['Xawery Żuławski (born 22 December 1971 in Warsaw) is a Polish film director.',\n",
       "   'In 1995 he graduated National Film School in Łódź.',\n",
       "   'He is the son of actress Małgorzata Braunek and director Andrzej Żuławski.',\n",
       "   'His second feature \"Wojna polsko-ruska\" (2009), adapted from the controversial best-selling novel by Dorota Masłowska, won First Prize in the New Polish Films competition at the 9th Era New Horizons Film Festival in Wrocław.',\n",
       "   'In 2013, he stated he intends to direct a Polish novel \"Zły\" by Leopold Tyrmand.',\n",
       "   'Żuławski and his wife Maria Strzelecka had 2 children together:',\n",
       "   'son Kaj Żuławski (born 2002) and daughter Jagna Żuławska (born 2009).'],\n",
       "  ['Snow White and the Seven Dwarfs( USA:\" Snow White\") is a 1955 German film, directed by Erich Kobler, based on the story of Schneewittchen by the Brothers Grimm.'],\n",
       "  ['Maheen Khan is a Pakistani fashion and costume designer, also an award winner fashion designer for fashion labels like\" The Embroidery HouseMaheen\" and\" Gulabo\".',\n",
       "   'She has done many national and international fashion events and shows.',\n",
       "   'She undertook embroidery for the film Snow White and the Huntsman and television series',\n",
       "   'The Jewel in the Crown.'],\n",
       "  ['A Snow White Christmas is a Christmas animated television special produced by Filmation and telecast December 19, 1980, on CBS.',\n",
       "   'It is a sequel to the fairy tale\" Snow White\", unrelated to Filmation\\'s other sequel to\" Snow White\" titled\" Happily Ever After\"( 1990).',\n",
       "   \"The film's plot revolves around the return of the Wicked Queen, who is unexpectedly brought back to life during Christmas and casts an evil spell that freezes the entire land.\",\n",
       "   'Only the young Snow White, the daughter of the original Snow White, manages to escape and take refuge with the seven giants with her dwarf friend.',\n",
       "   'It is now up to the giants to defeat the Queen forever and save the kingdom.'],\n",
       "  ['Alice Washburn( 1860- 1929) was an American stage and film actress.',\n",
       "   'She worked at the Edison, Vitagraph and Kalem studios.',\n",
       "   'Her final film Snow White was her only known feature film.',\n",
       "   'She died of heart attack in November 1929.'],\n",
       "  ['Polish-Russian War',\n",
       "   '(Wojna polsko-ruska) is a 2009 Polish film directed by Xawery Żuławski based on the novel Polish-Russian War under the white-red flag by Dorota Masłowska.'],\n",
       "  ['Viktor Petrovich Yeliseyev( born June 9, 1950) is a Russian general, orchestra conductor and music teacher.',\n",
       "   'He is the director of the Ministry of the Interior Ensemble, one of the two Russian Red Army Choirs.'],\n",
       "  ['She was the mother of Prince Morinaga.'],\n",
       "  ['Liberty Lettice Lark Ross( born 23 September 1978) is an English model and actress.',\n",
       "   'She has appeared in publications such as\" VogueHarper\\'s Bazaari- D\", and\" Dazed& Confused\".',\n",
       "   'She played the role of Queen Eleanor in the 2012 fantasy film\" Snow White and the Huntsman\", directed by her then- husband, Rupert Sanders.',\n",
       "   'She is the sister of composers Atticus and Leopold Ross.'],\n",
       "  ['Snow White and the Three Stooges is the second feature film to star the Three Stooges after their 1959 resurgence in popularity.',\n",
       "   'By this time, the trio consisted of Moe Howard, Larry Fine, and Joe DeRita( dubbed\" Curly Joe\").',\n",
       "   'Released by 20th Century Fox, this was the trio\\'s take on the classic fairy tale\" Snow White and the Seven Dwarfs\".',\n",
       "   'The film was retitled Snow White and the Three Clowns in Great Britain.',\n",
       "   'This was Walter Lang ‘s final directing film before his retirement.',\n",
       "   'Olympic gold medalist figure skater Carol Heiss starred as Snow White, who must flee her home after The Evil Queen, her evil stepmother, wishes her to be dead.',\n",
       "   'Seeking refuge in the cottage of the seven dwarfs, she accidentally meets the Stooges, who are house sitting for them while they are away.']],\n",
       " 'answers': 'Małgorzata Braunek',\n",
       " 'golds': 'Małgorzata Braunek',\n",
       " 'instruction': 'Answer the following question. Just output the answer (even if you are not sure), do not say anything else.\\nWho is the mother of the director of film Polish-Russian War (Film)?',\n",
       " 'output': 'Krystyna Janda',\n",
       " 'metric_result': 0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "from metrics import *\n",
    "\n",
    "file_path = \"/shared/eng/pj20/firas_data/test_datasets/results/2wikimultihop_sonnet_base.jsonl\"\n",
    "data = load_file(file_path)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.40013026352732234\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "    item[\"golds\"] = [item[\"golds\"]]\n",
    "    metric_result = f1_score(item[\"output\"], item[\"golds\"])\n",
    "    item[\"metric_result\"] = metric_result\n",
    "\n",
    "print(\"F1: \", np.mean([item[\"metric_result\"] for item in data]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS token: <|begin_of_text|>\n",
      "EOS token: <|end_of_text|>\n",
      "Special tokens: {'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "print(f\"BOS token: {tokenizer.bos_token}\")\n",
    "print(f\"EOS token: {tokenizer.eos_token}\")\n",
    "print(f\"Special tokens: {tokenizer.special_tokens_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
